#Intro To Miniflow

By building miniflow, a neural network library, will demystify two concepts at the heart of neural networks - **Back-Propagation** and **Differentiable Graphs**.

-

**Back-Propagation** is the process by which neural networks update the weights of the network over time.

**Differentiable Graphs** are graphs where the nodes are differentiable functions. They are also useful as visual aids for understanding and calculating complicated derivatives. This is the fundamental abstraction of TensorFlow - it's a framework for creating differentiable graphs.

-

With graphs and back-propagation, you will be able to create your own nodes and properly compute the derivatives. Even more importantly, you will be able to think and reason in terms of these graphs.
